
input {

jdbc {
    jdbc_driver_library => "${JDBC_DRIVER_LIBRARY}"
    jdbc_driver_class => "${JDBC_DRIVER_CLASS}"
    jdbc_connection_string => "jdbc:sqlserver://${SQLSERVERHOSTNAME}:${SQLSERVERPORT};instance=${SQLSERVERINSTANCE};databaseName=BluePrismTraining;integratedSecurity=true;useTicketCache=true;doNotPrompt=true;"
	#clean_run => true
	last_run_metadata_path => "${LOGSTASH_HOME}\.logstash_jdbc_last_run.audit"
	jdbc_user => "${JDBC_USER}"
      	schedule => "0 0 0-23 * * *"
	tracking_column => "eventdatetime"
	tracking_column_type => "timestamp"
	jdbc_default_timezone => "America/Toronto"
	statement => "select * from BPAAuditEvents where eventdatetime > :sql_last_value"
jdbc_paging_enabled => "true"
    jdbc_page_size => "50000"
    type => "blueprism.audit"
  }

   jdbc {
    jdbc_driver_library => "${JDBC_DRIVER_LIBRARY}"
    jdbc_driver_class => "${JDBC_DRIVER_CLASS}"
    jdbc_connection_string => "jdbc:sqlserver://${SQLSERVERHOSTNAME}:${SQLSERVERPORT};instance=${SQLSERVERINSTANCE};databaseName=${BLUEPRISMDB};integratedSecurity=true;useTicketCache=true;doNotPrompt=true;"
	#clean_run => true
	last_run_metadata_path => "${LOGSTASH_HOME}\.logstash_jdbc_last_run"
	jdbc_user => "${JDBC_USER}"
	#jdbc_password => "*******"
      	schedule => "0 0-59 0-23 * * *"
	tracking_column => "processenddatetime"
	tracking_column_type => "timestamp"
jdbc_default_timezone => "America/Toronto"
statement => "select L.*, S.statusid, Z.description as 'status',S.starterresourcename,S.starterusername,S.runningresourcename, S.runningosusername,S.startdatetime as 'processstartdatetime',S.enddatetime as 'processenddatetime',S.processname as 'processprocessname',
 datediff_big(ms, L.startdatetime,L.enddatetime)/1000.0 as 'duration',datediff_big(ms, S.startdatetime,S.enddatetime)/1000.0 as 'processduration' 
 from BPASessionLog_NonUnicode L join BPVSessioninfo S on S.sessionnumber = L.sessionnumber join BPAStatus Z on S.statusid = Z.statusid
where S.enddatetime > :sql_last_value and S.enddatetime is not null"
 
	jdbc_paging_enabled => "true"
    jdbc_page_size => "50000"
    type => "blueprism.process.completed"
  }
 jdbc {
    jdbc_driver_library => "${JDBC_DRIVER_LIBRARY}"
    jdbc_driver_class => "${JDBC_DRIVER_CLASS}"
    jdbc_connection_string => "jdbc:sqlserver://${SQLSERVERHOSTNAME}:${SQLSERVERPORT};instance=${SQLSERVERINSTANCE};databaseName=BluePrismTraining;integratedSecurity=true;useTicketCache=true;doNotPrompt=true;"
	#clean_run => true
	last_run_metadata_path => "${LOGSTASH_HOME}\.logstash_jdbc_last_run.running"
	jdbc_user => "${JDBC_USER}"
	#jdbc_password => "*******"
      	schedule => "0 0-59 0-23 * * *"
	tracking_column => "startdatetime"
	tracking_column_type => "timestamp"
jdbc_default_timezone => "America/Toronto"
statement => "select L.*, S.starterresourcename,S.starterusername,S.runningresourcename, S.runningosusername,S.startdatetime as 'processstartdatetime',S.enddatetime as 'processenddatetime',S.processname as 'processprocessname',
 datediff_big(ms, L.startdatetime,L.enddatetime)/1000.0 as 'duration',datediff_big(ms, S.startdatetime,S.enddatetime)/1000.0 as 'processduration' 
 from BPASessionLog_NonUnicode L join BPVSessioninfo S on S.sessionnumber = L.sessionnumber
where  L.startdatetime > :sql_last_value and  S.enddatetime is null"
 
	jdbc_paging_enabled => "true"
    jdbc_page_size => "50000"
    type => "blueprism.process.running"
  }
  
 jdbc {
    jdbc_driver_library => "${JDBC_DRIVER_LIBRARY}"
    jdbc_driver_class => "${JDBC_DRIVER_CLASS}"
    jdbc_connection_string => "jdbc:sqlserver://${SQLSERVERHOSTNAME}:${SQLSERVERPORT};instance=${SQLSERVERINSTANCE};databaseName=BluePrismTraining;integratedSecurity=true;useTicketCache=true;doNotPrompt=true;"
	#clean_run => true
	last_run_metadata_path => "${LOGSTASH_HOME}\.logstash_jdbc_last_run.queue"
	jdbc_user => "${JDBC_USER}"
	#jdbc_password => "*******"
      	schedule => "0 0-59 0-23 * * *"
	tracking_column => "lastupdated"
	tracking_column_type => "timestamp"
jdbc_default_timezone => "America/Toronto"
statement => "select B.name as 'QueueName',A.* from BPAWorkQueueItem as A INNER JOIN BPAWorkQueue as B on B.id = A.queueid where lastupdated > :sql_last_value"
 
	jdbc_paging_enabled => "true"
    jdbc_page_size => "50000"
    type => "blueprism.queue"
  }
}
filter {
# BluePrism
if [type] =~ /blueprism.process/
  {
	
	grok{
	match => ["startdatetime", "%{DATE_US:[@metadata][filedate]}"]
}
grok{
	match => ["startdatetime", "%{YEAR:[@metadata][filedateYYYY]}[/-]%{MONTHNUM2:[@metadata][filedateMM]}[/-]%{MONTHDAY:[@metadata][filedateDD]}"]
	}
  }
if [type] =~ /blueprism.queue/
  {
	xml {#don't forget to install the plugin : logstash-plugin install logstash-filter-xml
		source => "data"
		target => "data_xml"
		store_xml => "true" # set to false if you don't want to store content in target
	}
  }
}
output {
if [type] =~ /blueprism/
{
	if "running" in [type] {
	    elasticsearch { 
		hosts => "http://${ELKMASTERHOSTNAME}:${ELKMASTERPORT}"
		index => "%{type}" 
		document_id => "%{sessionnumber}-%{seqnum}"
		doc_as_upsert => "true"
		user => elastic
		password => changeme
	    }
	}
	else if [type] =~ /queue/ {
	    elasticsearch { 
		hosts => "http://${ELKMASTERHOSTNAME}:${ELKMASTERPORT}"
		index => "%{type}-%{+YYYY.MM}" 
		document_id => "%{id}"
		doc_as_upsert => "false"
		user => elastic
		password => changeme
	    }
	}
	else if [type] =~ /audit/ {
	    elasticsearch { 
		hosts => "http://${ELKMASTERHOSTNAME}:${ELKMASTERPORT}"
		index => "%{type}-%{+YYYY.MM}" 
		document_id => "%{eventid}"
		doc_as_upsert => "false"
		user => elastic
		password => changeme
	    }
	}
	else{
	    elasticsearch { 
		hosts => "http://${ELKMASTERHOSTNAME}:${ELKMASTERPORT}"
# The classic is to create an indices per day and tp chose the day of ingesting the data to create the indices.
# However this approach does not necessarily fit the goal most of the time.
#		index => "%{type}-%{+YYYY.MM.dd}"
# based on the strategy to organize the indices, you may decide to create one indice per day of data or one indice per month or per year or whatever
# Option 1 : one indice per day
#		index => "%{type}-%{[@metadata][filedate]}" 
# Option 2 : one indice per month
		index => "%{type}-%{[@metadata][filedateYYYY]}-%{[@metadata][filedateMM]}" 
# Option 3 : one indice per year
#		index => "%{type}-%{[@metadata][filedateYYYY]}" 
		document_id => "%{sessionnumber}-%{seqnum}"
		doc_as_upsert => "true"
		user => elastic
		password => changeme

		}
	}
}
# delete processes that have been completed from the "blueprism.running" pipeline
if [type] == "blueprism.process.completed"
{
 elasticsearch { 
	action => "delete"
	hosts => "http://${ELKMASTERHOSTNAME}:${ELKMASTERPORT}"
#	index => "blueprism.process.running-%{+YYYY.MM.dd}"
#	index => "blueprism.process.running-%{[@metadata][filedate]}"
	index => "blueprism.process.running"

# this will position the record in the index based on the timestamp of the date the record was created and not the load time of the record
	document_id => "%{sessionnumber}-%{seqnum}"
	user => elastic
        password => changeme
    }
}

# display to the console any of the output stream, this can be commented for performance reason
	
  stdout { codec => rubydebug }
}

